{"data":{"edges":[],"nodes":[{"data":{"node":{"template":{"_type":"Component","memory":{"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"memory","value":"","display_name":"External Memory","advanced":true,"input_types":["Memory"],"dynamic":false,"info":"Retrieve messages from an external memory. If empty, it will use the Langflow tables.","title_case":false,"type":"other","_input_type":"HandleInput"},"tools":{"trace_as_metadata":true,"list":true,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"tools","value":"","display_name":"Tools","advanced":false,"input_types":["Tool"],"dynamic":false,"info":"These are the tools that the agent can use to help with tasks.","title_case":false,"type":"other","_input_type":"HandleInput"},"add_current_date_tool":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"add_current_date_tool","value":true,"display_name":"Current Date","advanced":true,"dynamic":false,"info":"If true, will add a tool to the agent that returns the current date.","title_case":false,"type":"bool","_input_type":"BoolInput","input_types":[]},"agent_description":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"agent_description","value":"A helpful assistant with access to the following tools:","display_name":"Agent Description [Deprecated]","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.","title_case":false,"copy_field":false,"type":"str","_input_type":"MultilineInput"},"agent_llm":{"tool_mode":false,"trace_as_metadata":true,"options":["Amazon Bedrock","Anthropic","Azure OpenAI","Google Generative AI","Groq","NVIDIA","OpenAI","SambaNova","Custom"],"options_metadata":[{"icon":"Amazon"},{"icon":"Anthropic"},{"icon":"Azure"},{"icon":"GoogleGenerativeAI"},{"icon":"Groq"},{"icon":"NVIDIA"},{"icon":"OpenAI"},{"icon":"SambaNova"},{"icon":"brain"}],"combobox":false,"dialog_inputs":{},"toggle":false,"required":false,"placeholder":"","show":true,"name":"agent_llm","value":"Google Generative AI","display_name":"Model Provider","advanced":false,"input_types":[],"dynamic":false,"info":"The provider of the language model that the agent will use to generate responses.","real_time_refresh":true,"title_case":false,"type":"str","_input_type":"DropdownInput"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v is not None}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false,"input_types":[]},"handle_parsing_errors":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"handle_parsing_errors","value":true,"display_name":"Handle Parse Errors","advanced":true,"dynamic":false,"info":"Should the Agent fix errors when reading user input for better processing?","title_case":false,"type":"bool","_input_type":"BoolInput","input_types":[]},"input_value":{"tool_mode":true,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"input_value","value":"","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The input provided by the user for the agent to process.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"max_iterations":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"max_iterations","value":15,"display_name":"Max Iterations","advanced":true,"dynamic":false,"info":"The maximum number of attempts the agent can make to complete its task before it stops.","title_case":false,"type":"int","_input_type":"IntInput","input_types":[]},"n_messages":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"n_messages","value":100,"display_name":"Number of Messages","advanced":true,"dynamic":false,"info":"Number of messages to retrieve.","title_case":false,"type":"int","_input_type":"IntInput","input_types":[]},"order":{"tool_mode":true,"trace_as_metadata":true,"options":["Ascending","Descending"],"options_metadata":[],"combobox":false,"dialog_inputs":{},"toggle":false,"required":false,"placeholder":"","show":true,"name":"order","value":"Ascending","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","title_case":false,"type":"str","_input_type":"DropdownInput","input_types":[]},"sender":{"tool_mode":false,"trace_as_metadata":true,"options":["Machine","User","Machine and User"],"options_metadata":[],"combobox":false,"dialog_inputs":{},"toggle":false,"required":false,"placeholder":"","show":true,"name":"sender","value":"Machine and User","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Filter by sender type.","title_case":false,"type":"str","_input_type":"DropdownInput","input_types":[]},"sender_name":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"sender_name","value":"","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Filter by sender name.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"session_id":{"tool_mode":false,"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"session_id","value":"","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The session ID of the chat. If empty, the current session ID parameter will be used.","title_case":false,"type":"str","_input_type":"MessageTextInput"},"system_prompt":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"system_prompt","value":"Você é um agente de triagem de atendimento ao cliente responsável por avaliar a gravidade e complexidade de uma solicitação enviada por um cliente.\n\nSua missão é decidir, com base no conteúdo da mensagem, se o atendimento deve continuar de forma automatizada ou precisa ser escalonado para um atendente humano.\n\nCritérios para encaminhamento a um humano:\n\nA solicitação contém reclamações graves ou recorrentes;\n\nIndica frustração evidente ou urgência crítica;\n\nEnvolve dados sensíveis, financeiros ou problemas não solucionados automaticamente;\n\nEstá fora da base de conhecimento ou limitações técnicas dos sistemas automáticos.\n\nRetorne apenas uma das opções abaixo, conforme avaliação:\n\n“Encaminhar para atendimento humano”\n\n“Não encaminhar, pode seguir automatizado”","display_name":"Agent Instructions","advanced":false,"input_types":["Message"],"dynamic":false,"info":"System Prompt: Initial instructions and context provided to guide the agent's behavior.","title_case":false,"copy_field":false,"type":"str","_input_type":"MultilineInput"},"template":{"tool_mode":false,"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"template","value":"{sender_name}: {text}","display_name":"Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.","title_case":false,"copy_field":false,"type":"str","_input_type":"MultilineInput"},"verbose":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"verbose","value":true,"display_name":"Verbose","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool","_input_type":"BoolInput","input_types":[]},"max_output_tokens":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"max_output_tokens","value":"","display_name":"Max Output Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate.","title_case":false,"type":"int","_input_type":"IntInput","input_types":[]},"model_name":{"tool_mode":false,"trace_as_metadata":true,"options":["learnlm-2.0-flash-experimental","gemma-3n-e4b-it","gemma-3n-e2b-it","gemma-3-4b-it","gemma-3-27b-it","gemma-3-1b-it","gemma-3-12b-it","gemini-pro-vision","gemini-exp-1206","gemini-2.5-pro-preview-tts","gemini-2.5-pro-preview-06-05","gemini-2.5-pro-preview-05-06","gemini-2.5-pro-preview-03-25","gemini-2.5-pro","gemini-2.5-flash-preview-tts","gemini-2.5-flash-preview-05-20","gemini-2.5-flash-preview-04-17-thinking","gemini-2.5-flash-preview-04-17","gemini-2.5-flash-lite-preview-06-17","gemini-2.5-flash","gemini-2.0-pro-exp-02-05","gemini-2.0-pro-exp","gemini-2.0-flash-thinking-exp-1219","gemini-2.0-flash-thinking-exp-01-21","gemini-2.0-flash-thinking-exp","gemini-2.0-flash-preview-image-generation","gemini-2.0-flash-lite-preview-02-05","gemini-2.0-flash-lite-preview","gemini-2.0-flash-lite-001","gemini-2.0-flash-lite","gemini-2.0-flash-exp-image-generation","gemini-2.0-flash-exp","gemini-2.0-flash-001","gemini-2.0-flash","gemini-1.5-pro-latest","gemini-1.5-pro-002","gemini-1.5-pro","gemini-1.5-flash-latest","gemini-1.5-flash-8b-latest","gemini-1.5-flash-8b-001","gemini-1.5-flash-8b","gemini-1.5-flash-002","gemini-1.5-flash","gemini-1.0-pro-vision-latest"],"options_metadata":[],"combobox":true,"dialog_inputs":{},"toggle":false,"required":false,"placeholder":"","show":true,"name":"model_name","value":"gemini-2.5-flash","display_name":"Model","advanced":false,"dynamic":false,"info":"To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.","real_time_refresh":false,"refresh_button":true,"title_case":false,"type":"str","_input_type":"DropdownInput","input_types":[]},"api_key":{"load_from_db":false,"required":true,"placeholder":"","show":true,"name":"api_key","value":"AIzaSyC3YPYOEa-mfVR_HT9-Ujar2MYL4ipzfnI","display_name":"Google API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The Google API Key to use for the Google Generative AI.","real_time_refresh":true,"title_case":false,"password":true,"type":"str","_input_type":"SecretStrInput"},"top_p":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"top_p","value":"","display_name":"Top P","advanced":true,"dynamic":false,"info":"The maximum cumulative probability of tokens to consider when sampling.","title_case":false,"type":"float","_input_type":"FloatInput","input_types":[]},"temperature":{"tool_mode":false,"min_label":"","max_label":"","min_label_icon":"","max_label_icon":"","slider_buttons":false,"slider_buttons_options":[],"slider_input":false,"range_spec":{"step_type":"float","min":0,"max":2,"step":0.01},"required":false,"placeholder":"","show":true,"name":"temperature","value":0.1,"display_name":"Temperature","advanced":true,"dynamic":false,"info":"Controls randomness. Lower values are more deterministic, higher values are more creative.","title_case":false,"type":"slider","_input_type":"SliderInput","input_types":[]},"n":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"n","value":"","display_name":"N","advanced":true,"dynamic":false,"info":"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.","title_case":false,"type":"int","_input_type":"IntInput","input_types":[]},"top_k":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"top_k","value":"","display_name":"Top K","advanced":true,"dynamic":false,"info":"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.","title_case":false,"type":"int","_input_type":"IntInput","input_types":[]},"tool_model_enabled":{"tool_mode":false,"trace_as_metadata":true,"list":false,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"tool_model_enabled","value":false,"display_name":"Tool Model Enabled","advanced":true,"dynamic":false,"info":"Whether to use the tool model.","title_case":false,"type":"bool","_input_type":"BoolInput","input_types":[]},"tools_metadata":{"tool_mode":false,"trace_as_metadata":true,"is_list":true,"list_add_label":"Add More","required":false,"placeholder":"","show":true,"name":"tools_metadata","value":[{"name":"Agent","description":"A helpful assistant with access to the following tools:","tags":["Agent"],"status":true,"display_name":"message_response","display_description":"Agent. message_response - Define the agent's instructions, then enter a task to complete using tools.","readonly":false,"args":{"input_value":{"default":"","description":"The input provided by the user for the agent to process.","title":"Input Value","type":"string"},"order":{"default":"Ascending","description":"Order of the messages.","enum":["Ascending","Descending"],"title":"Order","type":"string"}}}],"display_name":"Actions","advanced":false,"dynamic":false,"info":"Modify tool names and descriptions to help agents understand when to use each tool.","real_time_refresh":true,"title_case":false,"type":"tools","_input_type":"ToolsInput"}},"description":"Define the agent's instructions, then enter a task to complete using tools.","icon":"bot","base_classes":["Message"],"display_name":"Agente de Escalonamento","documentation":"","minimized":false,"custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Tool"],"selected":"Tool","name":"component_as_tool","hidden":false,"display_name":"Toolset","method":"to_toolkit","value":"__UNDEFINED__","cache":true,"required_inputs":null,"allows_loop":false,"options":null,"tool_mode":true}],"field_order":["agent_llm","max_tokens","model_kwargs","json_mode","model_name","openai_api_base","api_key","temperature","seed","max_retries","timeout","system_prompt","tools","input_value","handle_parsing_errors","verbose","max_iterations","agent_description","memory","sender","sender_name","n_messages","session_id","order","template","add_current_date_tool"],"beta":false,"legacy":false,"edited":false,"metadata":{},"tool_mode":true,"lf_version":"1.4.2","official":false},"showNode":true,"type":"Agent","id":"Agent-nmpxJ"},"id":"Agent-nmpxJ","position":{"x":0,"y":0},"type":"genericNode"}],"viewport":{"x":1,"y":1,"zoom":1}},"description":"Define the agent's instructions, then enter a task to complete using tools.","name":"Agente de Escalonamento","id":"Agent-nmpxJ","is_component":true,"last_tested_version":"1.4.2"}